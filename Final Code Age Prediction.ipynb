{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "import collections\n",
    "from itertools import chain\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_processed.csv', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[['AccountTweets', 'AccountFollowers', 'AccountFollowing', 'rt_count', 'urls_count',\n",
    "       'capital_count', 'tweet_length', 'punctuation_count', 'hashtag_count', \n",
    "       'emoji_count', 'laugh_count', 'swear_count',\n",
    "       'diff_words_count', 'abbr_count', 'count_13_18_pos',\n",
    "       'count_13_18_neg', 'count_19_22_pos', 'count_19_22_neg',\n",
    "       'count_23_29_pos', 'count_23_29_neg', 'count_30_pos', 'count_30_neg',\n",
    "       'nnp', 'nn', 'rb', 'in', 'fw', 'nnps', 'vbp', 'cd', 'vbd', 'md', 'vb',\n",
    "       'vbg', 'vbz', 'rbr', 'vbn', 'jjs', 'cc',\n",
    "       'site', 'creation_date', 'literal_emojis', \n",
    "                     'emoji0',\n",
    " 'emoji1',\n",
    " 'emoji2',\n",
    " 'emoji3',\n",
    " 'emoji4',\n",
    " 'emoji5',\n",
    " 'emoji6',\n",
    " 'emoji7',\n",
    " 'emoji8',\n",
    " 'emoji9',\n",
    " 'emoji10',\n",
    " 'emoji11',\n",
    " 'emoji12',\n",
    " 'emoji13',\n",
    " 'emoji14',\n",
    " 'emoji15',\n",
    " 'emoji16',\n",
    " 'emoji17',\n",
    " 'emoji18',\n",
    " 'emoji19',\n",
    " 'emoji20',\n",
    " 'emoji21',\n",
    " 'emoji22',\n",
    " 'emoji23',\n",
    " 'emoji24',\n",
    " 'emoji25',\n",
    " 'emoji26',\n",
    " 'emoji27',\n",
    " 'emoji28',\n",
    " 'emoji29',\n",
    " 'emoji30',\n",
    " 'emoji31',\n",
    " 'emoji32',\n",
    " 'emoji33',\n",
    " 'emoji34',\n",
    " 'emoji35',\n",
    " 'emoji36',\n",
    " 'emoji37',\n",
    " 'emoji38',\n",
    " 'emoji39',\n",
    " 'emoji40',\n",
    " 'emoji41',\n",
    " 'emoji42',\n",
    " 'emoji43',\n",
    " 'emoji44',\n",
    " 'emoji45',\n",
    " 'emoji46',\n",
    " 'emoji47',\n",
    " 'emoji48',\n",
    " 'emoji49',\n",
    " 'emoji50',\n",
    " 'emoji51',\n",
    " 'emoji52',\n",
    " 'emoji53',\n",
    " 'emoji54',\n",
    " 'emoji55',\n",
    " 'emoji56',\n",
    " 'emoji57',\n",
    " 'emoji58',\n",
    " 'emoji59',\n",
    " 'emoji60',\n",
    " 'emoji61',\n",
    " 'emoji62',\n",
    " 'emoji63',\n",
    " 'emoji64',\n",
    " 'emoji65',\n",
    " 'emoji66',\n",
    " 'emoji67',\n",
    " 'emoji68',\n",
    " 'emoji69',\n",
    " 'emoji70',\n",
    " 'emoji71',\n",
    " 'emoji72',\n",
    " 'emoji73',\n",
    " 'emoji74',\n",
    " 'emoji75',\n",
    " 'emoji76',\n",
    " 'emoji77',\n",
    " 'emoji78',\n",
    " 'emoji79',\n",
    " 'emoji80',\n",
    " 'emoji81',\n",
    " 'emoji82',\n",
    " 'emoji83',\n",
    " 'emoji84',\n",
    " 'emoji85',\n",
    " 'emoji86',\n",
    " 'emoji87',\n",
    " 'emoji88',\n",
    " 'emoji89',\n",
    " 'emoji90',\n",
    " 'emoji91',\n",
    " 'emoji92',\n",
    " 'emoji93',\n",
    " 'emoji94',\n",
    " 'emoji95',\n",
    " 'emoji96',\n",
    " 'emoji97',\n",
    " 'emoji98',\n",
    " 'emoji99']]\n",
    "labels = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features = preprocessing.normalize(features)\n",
    "normalized_features_df = pd.DataFrame(normalized_features)\n",
    "normalized_features_df.columns = features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels0 = []\n",
    "for i in data['Class']:\n",
    "    if i == 0:\n",
    "        labels0.append(1)\n",
    "    else:\n",
    "        labels0.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = []\n",
    "for i in data['Class']:\n",
    "    if i == 1:\n",
    "        labels1.append(1)\n",
    "    else:\n",
    "        labels1.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2 = []\n",
    "for i in data['Class']:\n",
    "    if i == 2:\n",
    "        labels2.append(1)\n",
    "    else:\n",
    "        labels2.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(normalized_features_df, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(n_estimators=100, max_depth = 7, learning_rate=0.05)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorings = ['accuracy', 'f1_macro', 'f1_micro', 'precision', 'recall']\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(n_estimators=100, max_depth = 7, learning_rate=0.05)\n",
    "cross_validate(model, X_train, y_train, scoring=scorings, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "matrix.diagonal()/matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb.plot_importance(model, max_num_features = 22, importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDFVector(dct_igm, review):\n",
    "    # Create a list of unique words\n",
    "    wordDict = sorted(dct_igm.keys())\n",
    "    tfidfVector = [0.0] * len(wordDict)\n",
    "    \n",
    "  # For each unique word, if it is in the review, store its TF-IDF value.\n",
    "    for i, word in enumerate(wordDict):\n",
    "        if word in review:\n",
    "            tfidfVector[i] = review[word]\n",
    "    return tfidfVector\n",
    "\n",
    "def computeCountDict(list_tf):\n",
    "    \n",
    "    \"\"\" Returns a dictionary whose keys are all the unique words in\n",
    "    the dataset and whose values count the number of reviews in which\n",
    "    the word appears.\n",
    "    \"\"\"\n",
    "    countDict = {}\n",
    "    # Run through each review's tf dictionary and increment countDict's (word, doc) pair\n",
    "    for review in list_tf:\n",
    "        for word in review:\n",
    "            if word in countDict:\n",
    "                countDict[word] += 1\n",
    "            else:\n",
    "                countDict[word] = 1\n",
    "    return countDict\n",
    "\n",
    "def computeReviewTFDict(review):\n",
    "    \"\"\" Returns a tf dictionary for each review whose keys are all\n",
    "    the unique words in the review and whose values are their\n",
    "    corresponding tf.\n",
    "    \"\"\"\n",
    "    # Counts the number of times the word appears in review\n",
    "    reviewTFDict = {}\n",
    "    for word in review:\n",
    "        if word in reviewTFDict:\n",
    "            reviewTFDict[word] += 1\n",
    "        else:\n",
    "            reviewTFDict[word] = 1\n",
    "    # Computes tf for each word\n",
    "    for word in reviewTFDict:\n",
    "        reviewTFDict[word] = reviewTFDict[word] / len(review)\n",
    "    return reviewTFDict\n",
    "\n",
    "def map_dict(dct_igm, review):\n",
    "    reviewTFDict = {}\n",
    "    output = list(map(dct_igm.get, review.keys()))\n",
    "    output = [0 if v is None else v for v in output]\n",
    "    output = [v/np.log(len(output)) for v in output]\n",
    "    \n",
    "    reviewTFDict = dict(zip(review.keys(), output))\n",
    "    return reviewTFDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IGM\n",
    "\n",
    "data_new = data[['Volgendaccount', 'Class']]\n",
    "\n",
    "following_ids = data_new['Volgendaccount']\n",
    "following_ids0 = data_new[data_new['Class']==0]['Volgendaccount']\n",
    "following_ids1 = data_new[data_new['Class']==1]['Volgendaccount']\n",
    "following_ids2 = data_new[data_new['Class']==2]['Volgendaccount']\n",
    "\n",
    "data0 = [\n",
    "    [(word.replace(\",\", \"\")\n",
    "          .replace(\".\", \"\")\n",
    "          .replace(\"(\", \"\")\n",
    "          .replace(\")\", \"\")\n",
    "          .replace(\"]\", \"\")\n",
    "          .replace(\"[\", \"\"))\n",
    "    for word in row.lower().split()]\n",
    "    for row in following_ids0]\n",
    "\n",
    "data1 = [\n",
    "    [(word.replace(\",\", \"\")\n",
    "          .replace(\".\", \"\")\n",
    "          .replace(\"(\", \"\")\n",
    "          .replace(\")\", \"\")\n",
    "          .replace(\"]\", \"\")\n",
    "          .replace(\"[\", \"\"))\n",
    "    for word in row.lower().split()]\n",
    "    for row in following_ids1]\n",
    "\n",
    "data2 = [\n",
    "    [(word.replace(\",\", \"\")\n",
    "          .replace(\".\", \"\")\n",
    "          .replace(\"(\", \"\")\n",
    "          .replace(\")\", \"\")\n",
    "          .replace(\"]\", \"\")\n",
    "          .replace(\"[\", \"\"))\n",
    "    for word in row.lower().split()]\n",
    "    for row in following_ids2]\n",
    "\n",
    "data_all = [\n",
    "    [(word.replace(\",\", \"\")\n",
    "          .replace(\".\", \"\")\n",
    "          .replace(\"(\", \"\")\n",
    "          .replace(\")\", \"\")\n",
    "          .replace(\"]\", \"\")\n",
    "          .replace(\"[\", \"\"))\n",
    "    for word in row.lower().split()]\n",
    "    for row in following_ids]\n",
    "\n",
    "list_tf = []\n",
    "list_tf0 = []\n",
    "list_tf1 = []\n",
    "list_tf2 = []\n",
    "for i in data_all:\n",
    "    list_tf.append(computeReviewTFDict(i))\n",
    "for i in data0:\n",
    "    list_tf0.append(computeReviewTFDict(i))\n",
    "for i in data1:\n",
    "    list_tf1.append(computeReviewTFDict(i))\n",
    "for i in data2:\n",
    "    list_tf2.append(computeReviewTFDict(i))\n",
    "    \n",
    "countDict0 = computeCountDict(list_tf0)\n",
    "countDict1 = computeCountDict(list_tf1)\n",
    "countDict2 = computeCountDict(list_tf2)\n",
    "    \n",
    "df_counts0 = pd.DataFrame.from_dict(countDict0, orient='index')\n",
    "df_counts1 = pd.DataFrame.from_dict(countDict1, orient='index')\n",
    "df_counts2 = pd.DataFrame.from_dict(countDict2, orient='index')\n",
    "\n",
    "df = pd.concat([df_counts0, df_counts1, df_counts2], axis=1, sort=False)\n",
    "\n",
    "df = df.fillna(0)\n",
    "df.columns = ['counts0', 'counts1', 'counts2']\n",
    "df['sum'] = df.sum(axis=1)\n",
    "df['max'] = df[['counts0', 'counts1', 'counts2']].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_following = 1 # This was 5 in the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['counts0'] >= min_following]\n",
    "df = df[df['counts1'] >= min_following]\n",
    "df = df[df['counts2'] >= min_following]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['igm'] = df['max']/df['sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['counts1'] == df['max']].sort_values('igm', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 163730859 => @JackJ\n",
    "\n",
    "# 308297673 => @KianLawley\n",
    "\n",
    "# 405728790 => @camerondallas\n",
    "\n",
    "# 216430965 => @Caspar_Lee\n",
    "\n",
    "# 3105826730 => @DemetriusHarmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 34900333 => @jennajameson\n",
    "\n",
    "# 19339713 => @timlovejoy\n",
    "\n",
    "# 15901190 => @trent_reznor\n",
    "\n",
    "# 91208190 => @MelKiperESPN\n",
    "\n",
    "# 308981378 => @JohnHartson10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 112047805 => @brithume\n",
    "\n",
    "# 223970563 => @TeamCavuto\n",
    "\n",
    "# 15220768 => @DavidCornDC\n",
    "\n",
    "# 232901331 => @dbongino\n",
    "\n",
    "# 56561449 => @JesseBWatters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_igm = dict(zip(df.index,df['igm']))\n",
    "for i in dct_igm:\n",
    "    if i == 1.0:\n",
    "        i = 0\n",
    "        \n",
    "users_mapped = []\n",
    "for i in list_tf:\n",
    "    users_mapped.append(map_dict(dct_igm, i))\n",
    "    \n",
    "igm_result = [computeTFIDFVector(dct_igm, account_id) for account_id in users_mapped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igm_array = np.array(igm_result)\n",
    "igm_df = pd.DataFrame(igm_array)\n",
    "normalized_igm = preprocessing.normalize(igm_df)\n",
    "normalized_igm_df = pd.DataFrame(normalized_igm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_igm = []\n",
    "for i in range(len(normalized_igm_df.columns)):\n",
    "    columns_igm.append('igm'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_igm_df.columns = columns_igm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igm_features_normalized=pd.concat([normalized_igm_df,normalized_features_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(igm_features_normalized, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=5000,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "matrix.diagonal()/matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorings = ['accuracy', 'f1_macro', 'f1_micro', 'precision', 'recall']\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=5000,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False, random_state=0)\n",
    "cross_validate(model, X_train, y_train, scoring=scorings, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = []\n",
    "for tweets in data['Tweets']:\n",
    "    rt = 0\n",
    "    tweets_user = []\n",
    "    for i in range(len(tweets.split(\"\\'\"))):\n",
    "        tweet_fragment = tweets.split(\"\\'\")[i]\n",
    "        if tweet_fragment.count('RT') != 0:\n",
    "            x = 1\n",
    "        else:\n",
    "            tweets_user.append(tweet_fragment)\n",
    "    all_tweets.append(' '.join(tweets_user))\n",
    "    \n",
    "    if len(all_tweets) % 1000 == 0:\n",
    "        print(len(all_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets = []\n",
    "\n",
    "for tweet in all_tweets:\n",
    "    \n",
    "    tweet_no_link = re.sub(r'http\\S+', '', tweet)\n",
    "    tweet_stripped = tweet_no_link.lower().translate(str.maketrans('', '', '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~')).strip()\n",
    "    clean_tweet = re.sub(' +', ' ', tweet_stripped)\n",
    "    \n",
    "    clean_tweets.append(clean_tweet)\n",
    "    \n",
    "    if len(clean_tweets) % 1000 == 0:\n",
    "        print(len(clean_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tweets = []\n",
    "for tweet in clean_tweets:\n",
    "    no_handle = re.sub('(?:\\s)@[^, ]*', '', tweet)\n",
    "    no_hashtag = re.sub('(?:\\s)#[^, ]*', '', no_handle)\n",
    "    final_tweets.append(no_hashtag)\n",
    "    \n",
    "    if len(final_tweets) % 1000 == 0:\n",
    "        print(len(final_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sage_tweets'] = final_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "tweets_stemmed = []\n",
    "for tweet in data['sage_tweets']:\n",
    "    tokenAux=\"\"\n",
    "    textAux=\"\"\n",
    "    tokens = tweet.split()\n",
    "    for token in tokens:\n",
    "        tokenAux = token\n",
    "        tokenAux = stemmer.stem(token)    \n",
    "        textAux = textAux + \" \"+ tokenAux\n",
    "    tweets_stemmed.append(textAux)\n",
    "    \n",
    "    if len(tweets_stemmed) % 1000 == 0:\n",
    "        print(len(tweets_stemmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweets_stemmed'] = tweets_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# import en_core_web_sm\n",
    "\n",
    "import math\n",
    "from numpy.linalg import norm\n",
    "import copy\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "def adj_noun_merger(doc):\n",
    "    offset = 0\n",
    "    while offset < len(doc) - 3:\n",
    "        if doc[offset].pos_ in [\"ADJ\", \"NOUN\"] and doc[offset+1].pos_ == \"NOUN\":\n",
    "            start = doc[offset].i\n",
    "            if doc[offset+2].pos_ == 'NOUN':\n",
    "                if doc[offset+3].pos_ == 'NOUN': end = doc[offset+3].i\n",
    "                else: end = doc[offset+2].i \n",
    "            else: end = doc[offset+1].i\n",
    "            with doc.retokenize() as retokenizer:\n",
    "                retokenizer.merge(doc[start:end+1], attrs={\"POS\" : \"NOUN\"}) \n",
    "        offset += 1\n",
    "        \n",
    "def get_counters(left, right):\n",
    "    from collections import Counter\n",
    "    base_dict = {token : 1 for token in list(set(left + right))}\n",
    "    left_counts, right_counts = Counter(left), Counter(right)\n",
    "    \n",
    "    left_dict, right_dict = base_dict.copy(), base_dict.copy()\n",
    "    left_dict.update(left_counts)\n",
    "    right_dict.update(right_counts)\n",
    "    \n",
    "    return left_dict, right_dict\n",
    "\n",
    "def topK(beta,vocab,K=10):\n",
    "    return [vocab[idx] for idx in (-beta).argsort()[:K]]\n",
    "\n",
    "# import SAGE\n",
    "\n",
    "def get_keywords(eta, vocab, min_len = 2, remove = []):\n",
    "    keywords = [i[0] for i in topK(eta,vocab,len(vocab)) if i[1] == 'NOUN' and len(i[0].split(' ')) >= min_len and not any(c in string.digits for c in i[0])]\n",
    "    for word in remove:\n",
    "        try: keywords.remove(word)\n",
    "        except ValueError: print(f'{word} not in keywords')\n",
    "    return keywords\n",
    "\n",
    "class DeltaIterator:\n",
    "    def __init__(s,max_its=100,thresh=1e-4,debug=False):\n",
    "        s.thresh = thresh\n",
    "        s.max_its = max_its\n",
    "        s.prev = None\n",
    "        s.done = False\n",
    "        s.its = 0\n",
    "        s.debug = debug\n",
    "\n",
    "    def update(s,x):\n",
    "        if s.prev is not None:\n",
    "            change = norm(x - s.prev) / (1e-6+norm(x))\n",
    "            if s.debug: print(s.its,'/',s.max_its,change)\n",
    "            if change < s.thresh: s.done = True\n",
    "        s.its += 1\n",
    "        if s.its > s.max_its: s.done = True\n",
    "        s.prev = copy.copy(x)\n",
    "\n",
    "def estimate(ecounts,eq_m,max_its=25):\n",
    "    if len(ecounts.shape)==1:\n",
    "        ecounts = np.reshape(ecounts,(-1,1))\n",
    "    [W,K] = ecounts.shape\n",
    "    eta = np.zeros(W)\n",
    "    eq_inv_tau = np.ones(W)\n",
    "    exp_eq_m = np.exp(eq_m)\n",
    "    max_inv_tau = 1e5\n",
    "    it = DeltaIterator(debug=False,max_its=max_its,thresh=1e-4)\n",
    "    while not(it.done):\n",
    "        fLogNormal = lambda x : fLogNormalAux(x,ecounts,exp_eq_m,eq_inv_tau)\n",
    "        gLogNormal = lambda x : gLogNormalAux(x,ecounts,exp_eq_m,eq_inv_tau)\n",
    "        min_out = minimize(fLogNormal,eta,method='L-BFGS-B',jac=gLogNormal,options={'disp':False})\n",
    "        #TODO:\n",
    "        #hpLogNormal = lambda x : hpLogNormalAux(x,ecounts,exp_eq_m,eq_inv_tau)\n",
    "        #min_out = minimize(fLogNormal,eta,method='Newton-CG',jac=gLogNormal,options={'disp':True})\n",
    "        eta = min_out.x\n",
    "        eq_inv_tau = 1/(eta**2)\n",
    "        eq_inv_tau[eq_inv_tau > max_inv_tau] = max_inv_tau\n",
    "        it.update(eta)\n",
    "    return(eta)\n",
    "\n",
    "def fLogNormalAux(eta,ecounts,exp_eq_m,eq_inv_tau):\n",
    "    C = ecounts.sum(axis=0)\n",
    "    [W,K] = ecounts.shape\n",
    "    denom = np.tile(np.exp(eta),(K,1)).dot(exp_eq_m.T)\n",
    "    out = -(eta.T.dot(ecounts).sum(axis=0) - C * np.log(denom.sum(axis=0)) - 0.5 * eq_inv_tau.T.dot(eta ** 2))\n",
    "    return(out[0])\n",
    "           \n",
    "def gLogNormalAux(eta,ecounts,exp_eq_m,eq_inv_tau):\n",
    "    C = ecounts.sum(axis=0)\n",
    "    [W,K] = ecounts.shape\n",
    "    denom = np.tile(np.exp(eta),(K,1)) * exp_eq_m\n",
    "    denom_norm = (denom.T / denom.sum(axis=1))\n",
    "    beta = C * denom_norm / (C + 1e-10)\n",
    "    g = -(ecounts.sum(axis=1) - beta.dot(C) - eq_inv_tau * eta)\n",
    "    return(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_teenagers = data[data['Class'] == 0]['tweets_stemmed']\n",
    "bio_students = data[data['Class'] == 1]['tweets_stemmed']\n",
    "bio_adults = data[data['Class'] == 2]['tweets_stemmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_teenagers = bio_teenagers.str.cat(sep=' ')\n",
    "bio_students = bio_students.str.cat(sep=' ')\n",
    "bio_adults = bio_adults.str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_random_teenagers = bio_students + bio_adults\n",
    "bio_random_students = bio_teenagers + bio_adults\n",
    "bio_random_adults = bio_students + bio_teenagers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_teenagers = word_tokenize(bio_teenagers)\n",
    "tokens_students = word_tokenize(bio_students)\n",
    "tokens_adults = word_tokenize(bio_adults)\n",
    "\n",
    "tokens_random_teenagers = word_tokenize(bio_random_teenagers)\n",
    "tokens_random_students = word_tokenize(bio_random_students)\n",
    "tokens_random_adults = word_tokenize(bio_random_adults)\n",
    "\n",
    "teenage_counter, teenage_random_counter = get_counters(tokens_teenagers, tokens_random_teenagers)\n",
    "vocab_teenage = [word for word,count in Counter(teenage_counter).most_common(2000)]\n",
    "\n",
    "students_counter, students_random_counter = get_counters(tokens_students, tokens_random_students)\n",
    "vocab_students = [word for word,count in Counter(students_counter).most_common(2000)]\n",
    "\n",
    "adults_counter, adults_random_counter = get_counters(tokens_adults, tokens_random_adults)\n",
    "vocab_adults = [word for word,count in Counter(adults_counter).most_common(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teenagers = np.array([teenage_counter[word] for word in vocab_teenage])\n",
    "x_students = np.array([students_counter[word] for word in vocab_students])\n",
    "x_adults = np.array([adults_counter[word] for word in vocab_adults])\n",
    "\n",
    "x_random_teenagers = np.array([teenage_random_counter[word] for word in vocab_teenage]) + 1.\n",
    "x_random_students = np.array([students_random_counter[word] for word in vocab_students]) + 1.\n",
    "x_random_adults = np.array([adults_random_counter[word] for word in vocab_adults]) + 1.\n",
    "\n",
    "mu_teenage = np.log(x_random_teenagers) - np.log(x_random_teenagers.sum())\n",
    "mu_students = np.log(x_random_students) - np.log(x_random_students.sum())\n",
    "mu_adults = np.log(x_random_adults) - np.log(x_random_adults.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_teenage = estimate(x_teenagers,mu_teenage)\n",
    "eta_students = estimate(x_students,mu_students)\n",
    "eta_adults = estimate(x_adults,mu_adults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_teenage= dict(zip(vocab_teenage,eta_teenage))\n",
    "dct_students= dict(zip(vocab_students,eta_students))\n",
    "dct_adults= dict(zip(vocab_adults,eta_adults))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for i in data['tweets_stemmed']:\n",
    "# for i in data['clean_tweets']:\n",
    "    tokens_user = word_tokenize(str(i))\n",
    "    word_dct = {}\n",
    "    for word in tokens_user:\n",
    "        word_dct[word] = 0\n",
    "    all_words.append(word_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_mapped_teenage = []\n",
    "for i in all_words:\n",
    "    words_mapped_teenage.append(map_dict(dct_teenage, i))\n",
    "    \n",
    "words_mapped_students = []\n",
    "for i in all_words:\n",
    "    words_mapped_students.append(map_dict(dct_students, i))\n",
    "    \n",
    "words_mapped_adults = []\n",
    "for i in all_words:\n",
    "    words_mapped_adults.append(map_dict(dct_adults, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_result_teenage = [computeTFIDFVector(dct_teenage, user) for user in words_mapped_teenage]\n",
    "sage_result_students = [computeTFIDFVector(dct_students, user) for user in words_mapped_students]\n",
    "sage_result_adults = [computeTFIDFVector(dct_adults, user) for user in words_mapped_adults]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_teenage = np.array(sage_result_teenage)\n",
    "array_students = np.array(sage_result_students)\n",
    "array_adults = np.array(sage_result_adults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = np.column_stack([array_teenage, array_students, array_adults])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sage = pd.DataFrame(combined)\n",
    "indices_to_keep = ~df_sage.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "df_sage_clean = df_sage[indices_to_keep].astype(np.float64)\n",
    "normalized_sage = preprocessing.normalize(df_sage_clean)\n",
    "normalized_sage_df = pd.DataFrame(normalized_sage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_clean = pd.DataFrame(labels).reset_index()[indices_to_keep]['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igm_features_normalized_kept = igm_features_normalized[indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igm_features_normalized_kept.index = normalized_sage_df.index \n",
    "normalized_sage_df.reset_index(drop=True, inplace=True)\n",
    "all_features=pd.concat([normalized_sage_df,igm_features_normalized_kept], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_features, labels_clean, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False, random_state=0)# , \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "matrix.diagonal()/matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorings = ['accuracy', 'f1_macro', 'f1_micro', 'precision', 'recall']\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=5000,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False, random_state=0)\n",
    "cross_validate(model, X_train, y_train, scoring=scorings, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_new = all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_new['labels'] = labels_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_scores = []\n",
    "# for i in range(1000, 9500, 500):\n",
    "#     sample = all_features_new.sample(i)\n",
    "    \n",
    "# #     X_train, X_test, y_train, y_test = train_test_split(sample.iloc[:,:(len(sample.columns)-1)], sample['labels'], test_size=0.2)\n",
    "    \n",
    "\n",
    "#     model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "#                        intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
    "#                        multi_class='auto', n_jobs=None, penalty='l2',\n",
    "#                        solver='lbfgs', tol=0.0001, verbose=0,\n",
    "#                        warm_start=False, random_state=0)# , \n",
    "    \n",
    "#     scores = cross_val_score(model, sample.iloc[:,:(len(sample.columns)-1)], sample['labels'], cv=5, scoring='f1_macro')\n",
    "#     f1_scores.append(scores.mean())\n",
    "# #     y_pred = model.predict(X_test)\n",
    "# #     conf_mat = confusion_matrix(y_test, y_pred)\n",
    "# #     f1_scores.append(metrics.f1_score(y_test,y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.7065050863020835,\n",
    "#  0.7277652530808036,\n",
    "#  0.7433320330531445,\n",
    "#  0.7428359447186145,\n",
    "#  0.7348988415913787,\n",
    "#  0.7445765332468621,\n",
    "#  0.7561212310164757,\n",
    "#  0.7486918369390481,\n",
    "#  0.7563914236012406,\n",
    "#  0.7527007518167743,\n",
    "#  0.7574730386507367,\n",
    "#  0.7585046772120647,\n",
    "#  0.7573845049163584,\n",
    "#  0.7626483913823713,\n",
    "#  0.7676319321924464,\n",
    "#  0.764989555893724,\n",
    "#  0.7679941525589526"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topK(eta_adults, vocab_adults, K=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topK(eta_students, vocab_students, K=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topK(eta_teenage, vocab_teenage, K=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
