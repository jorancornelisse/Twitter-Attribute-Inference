{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "\n",
    "# import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "import collections\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# import en_core_web_sm\n",
    "\n",
    "import math\n",
    "from numpy.linalg import norm\n",
    "import copy\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDFVector(dct_igm, review):\n",
    "    # Create a list of unique words\n",
    "    wordDict = sorted(dct_igm.keys())\n",
    "    tfidfVector = [0.0] * len(wordDict)\n",
    "    \n",
    "  # For each unique word, if it is in the review, store its TF-IDF value.\n",
    "    for i, word in enumerate(wordDict):\n",
    "        if word in review:\n",
    "            tfidfVector[i] = review[word]\n",
    "    return tfidfVector\n",
    "\n",
    "def computeCountDict(list_tf):\n",
    "    \n",
    "    \"\"\" Returns a dictionary whose keys are all the unique words in\n",
    "    the dataset and whose values count the number of reviews in which\n",
    "    the word appears.\n",
    "    \"\"\"\n",
    "    countDict = {}\n",
    "    # Run through each review's tf dictionary and increment countDict's (word, doc) pair\n",
    "    for review in list_tf:\n",
    "        for word in review:\n",
    "            if word in countDict:\n",
    "                countDict[word] += 1\n",
    "            else:\n",
    "                countDict[word] = 1\n",
    "    return countDict\n",
    "\n",
    "def computeReviewTFDict(review):\n",
    "    \"\"\" Returns a tf dictionary for each review whose keys are all\n",
    "    the unique words in the review and whose values are their\n",
    "    corresponding tf.\n",
    "    \"\"\"\n",
    "    # Counts the number of times the word appears in review\n",
    "    reviewTFDict = {}\n",
    "    for word in review:\n",
    "        if word in reviewTFDict:\n",
    "            reviewTFDict[word] += 1\n",
    "        else:\n",
    "            reviewTFDict[word] = 1\n",
    "    # Computes tf for each word\n",
    "    for word in reviewTFDict:\n",
    "        reviewTFDict[word] = reviewTFDict[word] / len(review)\n",
    "    return reviewTFDict\n",
    "\n",
    "def map_dict(dct_igm, review):\n",
    "    reviewTFDict = {}\n",
    "    output = list(map(dct_igm.get, review.keys()))\n",
    "    output = [0 if v is None else v for v in output]\n",
    "    output = [v/np.log(len(output)) for v in output]\n",
    "    \n",
    "    reviewTFDict = dict(zip(review.keys(), output))\n",
    "    return reviewTFDict\n",
    "\n",
    "def adj_noun_merger(doc):\n",
    "    offset = 0\n",
    "    while offset < len(doc) - 3:\n",
    "        if doc[offset].pos_ in [\"ADJ\", \"NOUN\"] and doc[offset+1].pos_ == \"NOUN\":\n",
    "            start = doc[offset].i\n",
    "            if doc[offset+2].pos_ == 'NOUN':\n",
    "                if doc[offset+3].pos_ == 'NOUN': end = doc[offset+3].i\n",
    "                else: end = doc[offset+2].i \n",
    "            else: end = doc[offset+1].i\n",
    "            with doc.retokenize() as retokenizer:\n",
    "                retokenizer.merge(doc[start:end+1], attrs={\"POS\" : \"NOUN\"}) \n",
    "        offset += 1\n",
    "        \n",
    "def get_counters(left, right):\n",
    "    from collections import Counter\n",
    "    base_dict = {token : 1 for token in list(set(left + right))}\n",
    "    left_counts, right_counts = Counter(left), Counter(right)\n",
    "    \n",
    "    left_dict, right_dict = base_dict.copy(), base_dict.copy()\n",
    "    left_dict.update(left_counts)\n",
    "    right_dict.update(right_counts)\n",
    "    \n",
    "    return left_dict, right_dict\n",
    "\n",
    "def topK(beta,vocab,K=10):\n",
    "    return [vocab[idx] for idx in (-beta).argsort()[:K]]\n",
    "\n",
    "# import SAGE\n",
    "\n",
    "def get_keywords(eta, vocab, min_len = 2, remove = []):\n",
    "    keywords = [i[0] for i in topK(eta,vocab,len(vocab)) if i[1] == 'NOUN' and len(i[0].split(' ')) >= min_len and not any(c in string.digits for c in i[0])]\n",
    "    for word in remove:\n",
    "        try: keywords.remove(word)\n",
    "        except ValueError: print(f'{word} not in keywords')\n",
    "    return keywords\n",
    "\n",
    "class DeltaIterator:\n",
    "    def __init__(s,max_its=100,thresh=1e-4,debug=False):\n",
    "        s.thresh = thresh\n",
    "        s.max_its = max_its\n",
    "        s.prev = None\n",
    "        s.done = False\n",
    "        s.its = 0\n",
    "        s.debug = debug\n",
    "\n",
    "    def update(s,x):\n",
    "        if s.prev is not None:\n",
    "            change = norm(x - s.prev) / (1e-6+norm(x))\n",
    "            if s.debug: print(s.its,'/',s.max_its,change)\n",
    "            if change < s.thresh: s.done = True\n",
    "        s.its += 1\n",
    "        if s.its > s.max_its: s.done = True\n",
    "        s.prev = copy.copy(x)\n",
    "\n",
    "def estimate(ecounts,eq_m,max_its=25):\n",
    "    if len(ecounts.shape)==1:\n",
    "        ecounts = np.reshape(ecounts,(-1,1))\n",
    "    [W,K] = ecounts.shape\n",
    "    eta = np.zeros(W)\n",
    "    eq_inv_tau = np.ones(W)\n",
    "    exp_eq_m = np.exp(eq_m)\n",
    "    max_inv_tau = 1e5\n",
    "    it = DeltaIterator(debug=False,max_its=max_its,thresh=1e-4)\n",
    "    while not(it.done):\n",
    "        fLogNormal = lambda x : fLogNormalAux(x,ecounts,exp_eq_m,eq_inv_tau)\n",
    "        gLogNormal = lambda x : gLogNormalAux(x,ecounts,exp_eq_m,eq_inv_tau)\n",
    "        min_out = minimize(fLogNormal,eta,method='L-BFGS-B',jac=gLogNormal,options={'disp':False})\n",
    "        #TODO:\n",
    "        #hpLogNormal = lambda x : hpLogNormalAux(x,ecounts,exp_eq_m,eq_inv_tau)\n",
    "        #min_out = minimize(fLogNormal,eta,method='Newton-CG',jac=gLogNormal,options={'disp':True})\n",
    "        eta = min_out.x\n",
    "        eq_inv_tau = 1/(eta**2)\n",
    "        eq_inv_tau[eq_inv_tau > max_inv_tau] = max_inv_tau\n",
    "        it.update(eta)\n",
    "    return(eta)\n",
    "\n",
    "def fLogNormalAux(eta,ecounts,exp_eq_m,eq_inv_tau):\n",
    "    C = ecounts.sum(axis=0)\n",
    "    [W,K] = ecounts.shape\n",
    "    denom = np.tile(np.exp(eta),(K,1)).dot(exp_eq_m.T)\n",
    "    out = -(eta.T.dot(ecounts).sum(axis=0) - C * np.log(denom.sum(axis=0)) - 0.5 * eq_inv_tau.T.dot(eta ** 2))\n",
    "    return(out[0])\n",
    "           \n",
    "def gLogNormalAux(eta,ecounts,exp_eq_m,eq_inv_tau):\n",
    "    C = ecounts.sum(axis=0)\n",
    "    [W,K] = ecounts.shape\n",
    "    denom = np.tile(np.exp(eta),(K,1)) * exp_eq_m\n",
    "    denom_norm = (denom.T / denom.sum(axis=1))\n",
    "    beta = C * denom_norm / (C + 1e-10)\n",
    "    g = -(ecounts.sum(axis=1) - beta.dot(C) - eq_inv_tau * eta)\n",
    "    return(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_processed.csv', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_gender = pd.read_excel('gender.top100.1to3grams_cleaned.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_women = list(bins_gender.iloc[:,0])\n",
    "bins_men = list(bins_gender.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_men_clean = []\n",
    "for i in bins_men:\n",
    "    bins_men_clean.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_bins_women = []\n",
    "count_bins_men = []\n",
    "\n",
    "\n",
    "for tweet in data['clean_tweets']:\n",
    "    \n",
    "    count_bins_women.append(sum(tweet.count(x) for x in bins_women))\n",
    "    count_bins_men.append(sum(tweet.count(x) for x in bins_men_clean))\n",
    "    \n",
    "    \n",
    "    if len(count_bins_men) % 100 == 0:\n",
    "        print(len(count_bins_men))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['count_bins_women_wwbp'] = count_bins_women\n",
    "data['count_bins_men_wwbp'] = count_bins_men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gender_guesser.detector as gender\n",
    "\n",
    "def detect_gender(names):\n",
    "    first_names = []\n",
    "    names = names.astype(str)\n",
    "    pred_names = []\n",
    "    for i in names:\n",
    "        i = i.split(\" \", 1)\n",
    "        first_names.append(i[0])\n",
    "    d = gender.Detector()\n",
    "    genders = []\n",
    "    for i in first_names:\n",
    "        genders.append(d.get_gender(i.lower().title()))\n",
    "        pred_names.append(i.lower().title())\n",
    "    return pred_names, genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = detect_gender(data['AccountNaam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Gender'] = preds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gender = data[(data['Gender'] == 'male') | (data['Gender'] == 'female')].reset_index().drop('index', axis=1) #['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gender['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gender.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gender['abbr_count'] = data_gender['abbr_count']*data_gender['tweet_length']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gender[data_gender['Gender']=='female']['abbr_count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gender[data_gender['Gender']=='female']['abbr_count'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['capital_count'] = data['capital_count']/data['tweet_length']\n",
    "data['punctuation_count'] = data['punctuation_count']/data['tweet_length']\n",
    "\n",
    "data['emoji_count'] = data['emoji_count']/data['tweet_length']\n",
    "data['laugh_count'] = data['laugh_count']/data['tweet_length']\n",
    "data['swear_count'] = data['swear_count']/data['tweet_length']\n",
    "data['diff_words_count'] = data['diff_words_count']/data['tweet_length']\n",
    "data['abbr_count'] = data['abbr_count']/data['tweet_length']\n",
    "\n",
    "data['count_13_18_pos'] = data['count_13_18_pos']/data['tweet_length']\n",
    "data['count_13_18_neg'] = data['count_13_18_neg']/data['tweet_length']\n",
    "data['count_19_22_pos'] = data['count_19_22_pos']/data['tweet_length']\n",
    "data['count_19_22_neg'] = data['count_19_22_neg']/data['tweet_length']\n",
    "data['count_23_29_pos'] = data['count_23_29_pos']/data['tweet_length']\n",
    "\n",
    "data['count_23_29_neg'] = data['count_23_29_neg']/data['tweet_length']\n",
    "data['count_30_pos'] = data['count_30_pos']/data['tweet_length']\n",
    "data['count_30_neg'] = data['count_30_neg']/data['tweet_length']\n",
    "data['literal_emojis'] = data['literal_emojis']/data['tweet_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_gender[['AccountTweets', 'AccountFollowers', 'AccountFollowing', 'rt_count', 'urls_count',\n",
    "       'capital_count', 'tweet_length', 'punctuation_count', 'hashtag_count', \n",
    "       'emoji_count', 'laugh_count', 'swear_count',\n",
    "       'diff_words_count', 'abbr_count', 'count_13_18_pos',\n",
    "       'count_13_18_neg', 'count_19_22_pos', 'count_19_22_neg',\n",
    "       'count_23_29_pos', 'count_23_29_neg', 'count_30_pos', 'count_30_neg',\n",
    "       'nnp', 'nn', 'rb', 'in', 'fw', 'nnps', 'vbp', 'cd', 'vbd', 'md', 'vb',\n",
    "       'vbg', 'vbz', 'rbr', 'vbn', 'jjs', 'cc',\n",
    "       'site', 'creation_date', 'literal_emojis', \n",
    "                     'emoji0', 'count_bins_women_wwbp', 'count_bins_men_wwbp',\n",
    " 'emoji1',\n",
    " 'emoji2',\n",
    " 'emoji3',\n",
    " 'emoji4',\n",
    " 'emoji5',\n",
    " 'emoji6',\n",
    " 'emoji7',\n",
    " 'emoji8',\n",
    " 'emoji9',\n",
    " 'emoji10',\n",
    " 'emoji11',\n",
    " 'emoji12',\n",
    " 'emoji13',\n",
    " 'emoji14',\n",
    " 'emoji15',\n",
    " 'emoji16',\n",
    " 'emoji17',\n",
    " 'emoji18',\n",
    " 'emoji19',\n",
    " 'emoji20',\n",
    " 'emoji21',\n",
    " 'emoji22',\n",
    " 'emoji23',\n",
    " 'emoji24',\n",
    " 'emoji25',\n",
    " 'emoji26',\n",
    " 'emoji27',\n",
    " 'emoji28',\n",
    " 'emoji29',\n",
    " 'emoji30',\n",
    " 'emoji31',\n",
    " 'emoji32',\n",
    " 'emoji33',\n",
    " 'emoji34',\n",
    " 'emoji35',\n",
    " 'emoji36',\n",
    " 'emoji37',\n",
    " 'emoji38',\n",
    " 'emoji39',\n",
    " 'emoji40',\n",
    " 'emoji41',\n",
    " 'emoji42',\n",
    " 'emoji43',\n",
    " 'emoji44',\n",
    " 'emoji45',\n",
    " 'emoji46',\n",
    " 'emoji47',\n",
    " 'emoji48',\n",
    " 'emoji49',\n",
    " 'emoji50',\n",
    " 'emoji51',\n",
    " 'emoji52',\n",
    " 'emoji53',\n",
    " 'emoji54',\n",
    " 'emoji55',\n",
    " 'emoji56',\n",
    " 'emoji57',\n",
    " 'emoji58',\n",
    " 'emoji59',\n",
    " 'emoji60',\n",
    " 'emoji61',\n",
    " 'emoji62',\n",
    " 'emoji63',\n",
    " 'emoji64',\n",
    " 'emoji65',\n",
    " 'emoji66',\n",
    " 'emoji67',\n",
    " 'emoji68',\n",
    " 'emoji69',\n",
    " 'emoji70',\n",
    " 'emoji71',\n",
    " 'emoji72',\n",
    " 'emoji73',\n",
    " 'emoji74',\n",
    " 'emoji75',\n",
    " 'emoji76',\n",
    " 'emoji77',\n",
    " 'emoji78',\n",
    " 'emoji79',\n",
    " 'emoji80',\n",
    " 'emoji81',\n",
    " 'emoji82',\n",
    " 'emoji83',\n",
    " 'emoji84',\n",
    " 'emoji85',\n",
    " 'emoji86',\n",
    " 'emoji87',\n",
    " 'emoji88',\n",
    " 'emoji89',\n",
    " 'emoji90',\n",
    " 'emoji91',\n",
    " 'emoji92',\n",
    " 'emoji93',\n",
    " 'emoji94',\n",
    " 'emoji95',\n",
    " 'emoji96',\n",
    " 'emoji97',\n",
    " 'emoji98',\n",
    " 'emoji99']]\n",
    "labels = data_gender['Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features = preprocessing.normalize(features)\n",
    "normalized_features_df = pd.DataFrame(normalized_features)\n",
    "normalized_features_df.columns = features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(normalized_features_df, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(n_estimators=100, max_depth = 7, learning_rate=0.05)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorings = ['accuracy', 'f1_macro', 'f1_micro', 'precision', 'recall']\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(n_estimators=100, max_depth = 7, learning_rate=0.05)\n",
    "cross_validate(model, X_train, y_train, scoring=scorings, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_importances = pd.DataFrame(model.feature_importances_,\n",
    "                               index = X_train.columns,\n",
    "                      columns=['importance']).sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb.plot_importance(model, max_num_features = 10, importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IGM\n",
    "\n",
    "data_new = data_gender[['Volgendaccount', 'Gender']]\n",
    "\n",
    "following_ids = data_new['Volgendaccount']\n",
    "following_ids0 = data_new[data_new['Gender']=='male']['Volgendaccount']\n",
    "following_ids1 = data_new[data_new['Gender']=='female']['Volgendaccount']\n",
    "# following_ids2 = data_new[data_new['Gender']==2]['Volgendaccount']\n",
    "\n",
    "data0 = [\n",
    "    [(word.replace(\",\", \"\")\n",
    "          .replace(\".\", \"\")\n",
    "          .replace(\"(\", \"\")\n",
    "          .replace(\")\", \"\")\n",
    "          .replace(\"]\", \"\")\n",
    "          .replace(\"[\", \"\"))\n",
    "    for word in row.lower().split()]\n",
    "    for row in following_ids0]\n",
    "\n",
    "data1 = [\n",
    "    [(word.replace(\",\", \"\")\n",
    "          .replace(\".\", \"\")\n",
    "          .replace(\"(\", \"\")\n",
    "          .replace(\")\", \"\")\n",
    "          .replace(\"]\", \"\")\n",
    "          .replace(\"[\", \"\"))\n",
    "    for word in row.lower().split()]\n",
    "    for row in following_ids1]\n",
    "\n",
    "# data2 = [\n",
    "#     [(word.replace(\",\", \"\")\n",
    "#           .replace(\".\", \"\")\n",
    "#           .replace(\"(\", \"\")\n",
    "#           .replace(\")\", \"\")\n",
    "#           .replace(\"]\", \"\")\n",
    "#           .replace(\"[\", \"\"))\n",
    "#     for word in row.lower().split()]\n",
    "#     for row in following_ids2]\n",
    "\n",
    "data_all = [\n",
    "    [(word.replace(\",\", \"\")\n",
    "          .replace(\".\", \"\")\n",
    "          .replace(\"(\", \"\")\n",
    "          .replace(\")\", \"\")\n",
    "          .replace(\"]\", \"\")\n",
    "          .replace(\"[\", \"\"))\n",
    "    for word in row.lower().split()]\n",
    "    for row in following_ids]\n",
    "\n",
    "list_tf = []\n",
    "list_tf0 = []\n",
    "list_tf1 = []\n",
    "# list_tf2 = []\n",
    "for i in data_all:\n",
    "    list_tf.append(computeReviewTFDict(i))\n",
    "for i in data0:\n",
    "    list_tf0.append(computeReviewTFDict(i))\n",
    "for i in data1:\n",
    "    list_tf1.append(computeReviewTFDict(i))\n",
    "# for i in data2:\n",
    "#     list_tf2.append(computeReviewTFDict(i))\n",
    "    \n",
    "countDict0 = computeCountDict(list_tf0)\n",
    "countDict1 = computeCountDict(list_tf1)\n",
    "# countDict2 = computeCountDict(list_tf2)\n",
    "    \n",
    "df_counts0 = pd.DataFrame.from_dict(countDict0, orient='index')\n",
    "df_counts1 = pd.DataFrame.from_dict(countDict1, orient='index')\n",
    "# df_counts2 = pd.DataFrame.from_dict(countDict2, orient='index')\n",
    "\n",
    "df = pd.concat([df_counts0, df_counts1], axis=1, sort=False) # df_counts2\n",
    "\n",
    "df = df.fillna(0)\n",
    "df.columns = ['counts0', 'counts1'] #counts2\n",
    "df['sum'] = df.sum(axis=1)\n",
    "df['max'] = df[['counts0', 'counts1']].max(axis=1) # counts2\n",
    "\n",
    "max_following = 1 # This is 10 in the study\n",
    "\n",
    "df = df[df['counts0'] >= max_following]\n",
    "df = df[df['counts1'] >= max_following]\n",
    "# df = df[df['counts2'] >= 5]\n",
    "\n",
    "df['igm'] = df['max']/df['sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['counts0'] == df['max']].sort_values('igm', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 461922813 => @Ibra_official\n",
    "\n",
    "# 50323173 => @wojespn\n",
    "\n",
    "# 28870086 => @mortreport\n",
    "\n",
    "# 15332636 => @talkSPORT\n",
    "\n",
    "# 2835653131 => @miakhalifa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 243098820 => @ItsGaryTime\n",
    "\n",
    "# 386370914 => @ryancedwards\n",
    "\n",
    "# 15613133 => @Smashbox\n",
    "\n",
    "# 2391359107 => @AmberLPortwood\n",
    "\n",
    "# 251706984 => @PBandJenelley_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_igm = dict(zip(df.index,df['igm']))\n",
    "for i in dct_igm:\n",
    "    if i == 1.0:\n",
    "        i = 0\n",
    "        \n",
    "users_mapped = []\n",
    "for i in list_tf:\n",
    "    users_mapped.append(map_dict(dct_igm, i))\n",
    "    \n",
    "igm_result = [computeTFIDFVector(dct_igm, account_id) for account_id in users_mapped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igm_array = np.array(igm_result)\n",
    "igm_df = pd.DataFrame(igm_array)\n",
    "normalized_igm = preprocessing.normalize(igm_df)\n",
    "normalized_igm_df = pd.DataFrame(normalized_igm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igm_features_normalized=pd.concat([normalized_igm_df,normalized_features_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(igm_features_normalized, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=5000,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorings = ['accuracy', 'f1_macro', 'f1_micro', 'precision', 'recall']\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=5000,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False, random_state=0)\n",
    "cross_validate(model, X_train, y_train, scoring=scorings, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = []\n",
    "for tweets in data_gender['Tweets']:\n",
    "    rt = 0\n",
    "    tweets_user = []\n",
    "    for i in range(len(tweets.split(\"\\'\"))):\n",
    "        tweet_fragment = tweets.split(\"\\'\")[i]\n",
    "        if tweet_fragment.count('RT') != 0:\n",
    "            x = 1\n",
    "        else:\n",
    "            tweets_user.append(tweet_fragment)\n",
    "    all_tweets.append(' '.join(tweets_user))\n",
    "    \n",
    "    if len(all_tweets) % 1000 == 0:\n",
    "        print(len(all_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets = []\n",
    "\n",
    "for tweet in all_tweets:\n",
    "    \n",
    "    tweet_no_link = re.sub(r'http\\S+', '', tweet)\n",
    "    tweet_stripped = tweet_no_link.lower().translate(str.maketrans('', '', '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~')).strip()\n",
    "    clean_tweet = re.sub(' +', ' ', tweet_stripped)\n",
    "    \n",
    "    clean_tweets.append(clean_tweet)\n",
    "    \n",
    "    if len(clean_tweets) % 1000 == 0:\n",
    "        print(len(clean_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tweets = []\n",
    "for tweet in clean_tweets:\n",
    "    no_handle = re.sub('(?:\\s)@[^, ]*', '', tweet)\n",
    "    no_hashtag = re.sub('(?:\\s)#[^, ]*', '', no_handle)\n",
    "    final_tweets.append(no_hashtag)\n",
    "    \n",
    "    if len(final_tweets) % 1000 == 0:\n",
    "        print(len(final_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gender['sage_tweets'] = final_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "tweets_stemmed = []\n",
    "for tweet in data_gender['sage_tweets']:\n",
    "    tokenAux=\"\"\n",
    "    textAux=\"\"\n",
    "    tokens = tweet.split()\n",
    "    for token in tokens:\n",
    "        tokenAux = token\n",
    "        tokenAux = stemmer.stem(token)    \n",
    "        textAux = textAux + \" \"+ tokenAux\n",
    "    tweets_stemmed.append(textAux)\n",
    "    \n",
    "    if len(tweets_stemmed) % 1000 == 0:\n",
    "        print(len(tweets_stemmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gender['tweets_stemmed'] = tweets_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SAGE\n",
    "\n",
    "# Hier staat het dus goed, tweets\n",
    "tweets_male = data_gender[data_gender['Gender'] == 'male']['tweets_stemmed']\n",
    "tweets_female = data_gender[data_gender['Gender'] == 'female']['tweets_stemmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_male = tweets_male.str.cat(sep=' ')\n",
    "tweets_female = tweets_female.str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_male = tweets_male.lower()\n",
    "tweets_female = tweets_female.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_male = word_tokenize(tweets_male)\n",
    "tokens_female = word_tokenize(tweets_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_counter, male_random_counter = get_counters(tokens_male, tokens_female)\n",
    "vocab_male = [word for word,count in Counter(male_counter).most_common(2000)]\n",
    "\n",
    "female_counter, female_random_counter = get_counters(tokens_female, tokens_male)\n",
    "vocab_female = [word for word,count in Counter(female_counter).most_common(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_male = np.array([male_counter[word] for word in vocab_male])\n",
    "x_female = np.array([female_counter[word] for word in vocab_female])\n",
    "\n",
    "x_random_male = np.array([male_random_counter[word] for word in vocab_male]) + 1.\n",
    "x_random_female = np.array([female_random_counter[word] for word in vocab_female]) + 1.\n",
    "\n",
    "mu_male = np.log(x_random_male) - np.log(x_random_male.sum())\n",
    "mu_female = np.log(x_random_female) - np.log(x_random_female.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_male = estimate(x_male,mu_male)\n",
    "eta_female = estimate(x_female,mu_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_male= dict(zip(vocab_male,eta_male))\n",
    "dct_female= dict(zip(vocab_female,eta_female))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for i in data_gender['sage_tweets']:\n",
    "    tokens_user = word_tokenize(str(i))\n",
    "    word_dct = {}\n",
    "    for word in tokens_user:\n",
    "        word_dct[word] = 0\n",
    "    all_words.append(word_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_mapped_male = []\n",
    "for i in all_words:\n",
    "    words_mapped_male.append(map_dict(dct_male, i))\n",
    "    \n",
    "words_mapped_female = []\n",
    "for i in all_words:\n",
    "    words_mapped_female.append(map_dict(dct_female, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_result_male = [computeTFIDFVector(dct_male, user) for user in words_mapped_male]\n",
    "sage_result_female = [computeTFIDFVector(dct_female, user) for user in words_mapped_female]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_male = np.array(sage_result_male)\n",
    "array_female = np.array(sage_result_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = np.column_stack([array_male, array_female])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sage = pd.DataFrame(combined)\n",
    "indices_to_keep_tweets = ~df_sage.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "df_sage_clean = df_sage[indices_to_keep_tweets].astype(np.float64)\n",
    "normalized_tweets = preprocessing.normalize(df_sage_clean)\n",
    "normalized_tweets_df = pd.DataFrame(normalized_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_clean = pd.DataFrame(labels).reset_index()[indices_to_keep_tweets]['Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igm_features_normalized_kept = igm_features_normalized[indices_to_keep_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igm_features_normalized_kept.index = normalized_tweets_df.index \n",
    "\n",
    "#option 2\n",
    "#index of t starts from 0\n",
    "normalized_tweets_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#now concat will keep number of rows \n",
    "all_features=pd.concat([normalized_tweets_df,igm_features_normalized_kept], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_features, labels_clean, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False, random_state=0)# , \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "matrix.diagonal()/matrix.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorings = ['accuracy', 'f1_macro', 'f1_micro', 'precision', 'recall']\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=5000,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False, random_state=0)\n",
    "cross_validate(model, X_train, y_train, scoring=scorings, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_new = all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_new['labels'] = labels_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_scores = []\n",
    "# for i in range(1000, 6000, 500):\n",
    "#     sample = all_features_new.sample(i)\n",
    "    \n",
    "# #     X_train, X_test, y_train, y_test = train_test_split(sample.iloc[:,:(len(sample.columns)-1)], sample['labels'], test_size=0.2)\n",
    "    \n",
    "\n",
    "#     model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "#                        intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
    "#                        multi_class='auto', n_jobs=None, penalty='l2',\n",
    "#                        solver='lbfgs', tol=0.0001, verbose=0,\n",
    "#                        warm_start=False, random_state=0)# , \n",
    "    \n",
    "#     scores = cross_val_score(model, sample.iloc[:,:(len(sample.columns)-1)], sample['labels'], cv=5, scoring='f1_macro')\n",
    "#     f1_scores.append(scores.mean())\n",
    "# #     y_pred = model.predict(X_test)\n",
    "# #     conf_mat = confusion_matrix(y_test, y_pred)\n",
    "# #     f1_scores.append(metrics.f1_score(y_test,y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8004743500179003,\n",
    "#  0.8065622227425413,\n",
    "#  0.8084215280400642,\n",
    "#  0.8214528704084145,\n",
    "#  0.833778966773781,\n",
    "#  0.8320699144344921,\n",
    "#  0.8255984333414521,\n",
    "#  0.828508465992971,\n",
    "#  0.8306102667022429,\n",
    "#  0.8355304024973392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topK(eta_male, vocab_male, K=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topK(eta_female, vocab_female, K=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
